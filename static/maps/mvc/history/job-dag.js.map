{"version":3,"sources":["mvc/history/job-dag.js"],"names":["define","GRAPH","addLogging","_super","Graph","JobDAG","options","self","this","_jobsData","_historyContentsMap","_toolMap","noOutputJobs","filteredErroredJobs","filteredSetMetadata","_","pick","dataKeys","omit","prototype","init","excludeSetMetadata","defaults","call","filters","_initFilters","push","jobData","job","id","excludeErroredJobs","isArray","concat","length","read","data","has","preprocessHistoryContents","historyContents","preprocessTools","tools","createGraph","_filterJobs","info","forEach","content","i","clone","each","tool","preprocessJobs","jobs","_outputIdToJobMap","sort","map","preprocessJob","a","b","create_time","index","inputs","_processInputs","size","noInputJobs","outputs","_processOutputs","tool_id","inputMap","input","nameInJob","_validateInputOutput","name","inputOutput","Error","JSON","stringify","src","outputMap","output","filter","j","_filterJob","debug","jobsData","createVertex","targetId","inputId","sourceId","createJobLessVertex","createEdge","directed","dataset","toVerticesAndEdges","contentId","mangledId","weakComponentGraphArray","dag","weakComponents","component","vertices","aCreateTime","bCreateTime","_jobsDataMap","jobsDataMap"],"mappings":"aAAAA,QAAQ,cAAe,qBAAsB,SAASC,EAAOC,GAIzD,IAAIC,EAASF,EAAMG,MAKfC,EAAS,SAASC,GAClBA,EAAUA,MACV,IAAIC,EAAOC,KAAXD,EAAIA,WAOJA,EAAKE,aAFLF,EAAAG,uBACAH,EAAAI,YAEAJ,EAAKG,qBACLH,EAAKI,eAILJ,EAAKK,gBAALL,EAAKK,uBAILL,EAAKM,uBADLN,EAAKO,UAAAA,OAAL,kBAAA,SACAP,EAAKM,KAAAA,GAAAA,EAALE,EAAAC,KAAAV,EAAAC,EAAAU,UAAAF,EAAAG,KAAAZ,EAAAC,EAAAU,YA8SJ,OA5SIV,EAAAA,UAAA,IAAiBN,EAAQG,MACzBD,EAAAA,UAAYI,YAAcS,EAG9BX,EAAOc,GAOPd,EAAOc,UAAUC,KAAO,SAAed,GAFvCA,EAAAA,MAEAD,IAAOc,EAAAA,KAOHZ,OANAD,EAAAA,QAAUA,EAAAA,SAAVA,GAIIe,oBAAoB,IADxBd,EAAKD,QAAUS,EAAEO,eAAkBnB,EAAnCgB,UAAAC,KAAAG,KAAAhB,EAAAD,GAGKkB,GAIRnB,EAXDc,UAAAM,aAAA,WAeI,IAAIlB,EAAOC,KAFfgB,KA+BQA,OA7BAjB,EAAAA,QAAJc,qBACIG,EAAAA,uBAIAA,EAAQE,KAAK,SAA2BC,GAFxCpB,MAAJ,qBAASD,EAAQe,IAAAA,UAGTd,EAAIoB,oBAAAD,KAAwBC,EAAAC,IAAAC,KACxB,MAIPtB,EANDD,QAAAwB,qBAOHvB,EAAAM,uBAIGW,EAAQE,KAAK,SAAuBC,GAFpCpB,MAAauB,UAARxB,EAAQwB,IAAAA,QAGTvB,EAAIoB,oBAAAD,KAAsBC,EAASC,IAAAC,KAC/B,MAOZd,EAAAgB,QAAAxB,EAAAD,QAAAkB,WACAA,EAAAA,EAAAQ,OAAAzB,EAAAD,QAAAkB,UAEAjB,EAAIQ,MAAEgB,eAAqBP,EAA3BS,QACIT,GAIPnB,EAlCDc,UAAAe,KAAA,SAAAC,GAsCI,IAAI5B,EAAOC,KAFf,OAAAO,EAAAqB,IAAAD,EAAA,oBAAApB,EAAAqB,IAAAD,EAAA,SAAApB,EAAAqB,IAAAD,EAAA,UAGQpB,EACAsB,0BAAAF,EAAAG,qBACAC,gBAAAJ,EAAAK,WAEKH,eAAAA,EAAAA,UAKL9B,EAAKkC,YAAYlC,EAAKmC,eACfnC,GAEJJ,EAAOgB,UAAUe,KAAKX,KAAKf,KAAM2B,IAI5C9B,EAAOc,UAAUkB,0BAA4B,SAAoCC,GAC7E9B,KAAKmC,KAAK,sBACV,IAAIpC,EAAOC,KAMX,OALAD,EAAKG,uBAEL4B,EAAgBM,QAAQ,SAAAC,EAAAC,GACpBvC,EAAKG,oBAAoBmC,EAAQhB,IAAMd,EAAEgC,MAAMF,KAE5CtC,GAIXF,EAAOc,UAAUoB,gBAAkB,SAA0BC,GACzDhC,KAAKmC,KAAK,oBACV,IAAIpC,EAAOC,KAMX,OALAD,EAAKI,YAELI,EAAEiC,KAAKR,EAAO,SAAAS,EAAApB,GACVtB,EAAKI,SAASkB,GAAMd,EAAEgC,MAAME,KAEzB1C,GAIXF,EAAOc,UAAU+B,eAAiB,SAAyBC,GACvD3C,KAAKmC,KAAK,mBACV,IAAIpC,EAAOC,KAQX,OAPAD,EAAK6C,qBAEL7C,EAAKE,UAAYF,EAAK8C,KAAKF,GAAMG,IAAI,SAAA1B,GACjC,OAAOrB,EAAKgD,cAAcxC,EAAEgC,MAAMnB,MAI/BrB,GAIXF,EAAOc,UAAUkC,KAAO,SAAeF,GAUnC,OAAOA,EAAKE,KATZ,SAAmBG,EAAGC,GAClB,OAAID,EAAEE,YAAcD,EAAEC,YACX,EAEPF,EAAEE,YAAcD,EAAEC,aACV,EAEL,KAMfrD,EAAOc,UAAUoC,cAAgB,SAAwB3B,EAAK+B,GAE1D,IAAIpD,EAAOC,KACPmB,GAAYC,IAAKA,GAcrB,OAZAD,EAAQiC,OAASrD,EAAKsD,eAAejC,GACN,IAA3Bb,EAAE+C,KAAKnC,EAAQiC,SACfrD,EAAKwD,YAAYrC,KAAKE,EAAIC,IAE9BF,EAAQqC,QAAUzD,EAAK0D,gBAAgBrC,GACP,IAA5Bb,EAAE+C,KAAKnC,EAAQqC,UACfzD,EAAKK,aAAac,KAAKE,EAAIC,IAG/BF,EAAQsB,KAAO1C,EAAKI,SAASiB,EAAIsC,SAG1BvC,GAKXtB,EAAOc,UAAU0C,eAAiB,SAAyBjC,GACvD,IAAIrB,EAAOC,KACPoD,EAAShC,EAAIgC,OACbO,KAWJ,OAVApD,EAAEiC,KAAKY,EAAQ,SAAAQ,EAAAC,IACXD,EAAQrD,EAAEgC,MAAMxC,EAAK+D,qBAAqBF,KACpCG,KAAOF,EAKbD,EAAMvB,QAAUtC,EAAKG,oBAAoB0D,EAAMvC,IAC/CsC,EAASC,EAAMvC,IAAMuC,IAElBD,GAKX9D,EAAOc,UAAUmD,qBAAuB,SAA+BE,GACnE,IAAKA,EAAY3C,GACb,MAAM,IAAI4C,MAAM,8BAA+BC,KAAKC,UAAUH,IAElE,IAAKA,EAAYI,KAA2B,QAApBJ,EAAYI,IAChC,MAAM,IAAIH,MAAM,gCAAiCC,KAAKC,UAAUH,IAEpE,OAAOA,GAKXnE,EAAOc,UAAU8C,gBAAkB,SAA0BrC,GACzD,IAAIrB,EAAOC,KACPwD,EAAUpC,EAAIoC,QACda,KAUJ,OATA9D,EAAEiC,KAAKgB,EAAS,SAAAc,EAAAT,IACZS,EAAS/D,EAAEgC,MAAMxC,EAAK+D,qBAAqBQ,KACpCP,KAAOF,EAEdS,EAAOjC,QAAUtC,EAAKG,oBAAoBoE,EAAOjD,IACjDgD,EAAUC,EAAOjD,IAAMiD,EAEvBvE,EAAK6C,kBAAkB0B,EAAOjD,IAAMD,EAAIC,KAErCgD,GAIXxE,EAAOc,UAAUuB,YAAc,WAC3B,IAAInC,EAAOC,KACX,OAAOD,EAAKE,UAAUsE,OAAO,SAAAC,EAAAlC,GACzB,OAAOvC,EAAK0E,WAAWD,EAAGlC,MAMlCzC,EAAOc,UAAU8D,WAAa,SAAoBtD,EAASgC,GAGvD,IAAK,IADDpD,EAAOC,KACFsC,EAAI,EAAGA,EAAIvC,EAAKiB,QAAQS,OAAQa,IACrC,IAAKvC,EAAKiB,QAAQsB,GAAGvB,KAAKhB,EAAMoB,GAE5B,OADApB,EAAK2E,MAAM,SAAUvD,EAAQC,IAAIC,GAAI,wCAAyCtB,EAAKiB,QAAQsB,KACpF,EAGf,OAAO,GAMXzC,EAAOc,UAAUsB,YAAc,SAAsB0C,GACjD,IAAI5E,EAAOC,KA8BX,OA7BAD,EAAK2E,MAAM,gBAGXnE,EAAEiC,KAAKmC,EAAU,SAAAxD,GACb,IAAIE,EAAKF,EAAQC,IAAIC,GACrBtB,EAAK2E,MAAM,KAAMrD,EAAIF,GACrBpB,EAAK6E,aAAavD,EAAIF,KAE1BZ,EAAEiC,KAAKmC,EAAU,SAAAxD,GACb,IAAI0D,EAAW1D,EAAQC,IAAIC,GAC3Bd,EAAEiC,KAAKrB,EAAQiC,OAAQ,SAAAQ,EAAAkB,GAEnB,IAAIC,EAAWhF,EAAK6C,kBAAkBkC,GAEjCC,IAEDA,EADoBhF,EAAKiF,oBAAoBF,GACpBf,MAK7BhE,EAAKkF,WAAWF,EAAUF,EAAU9E,EAAKmF,UACrCC,QAASL,QAMrB/E,EAAK2E,MAAM,gBAAiBR,KAAKC,UAAUpE,EAAKqF,qBAAsB,KAAM,OACrErF,GAIXF,EAAOc,UAAUqE,oBAAsB,SAA8BK,GAGjE,IACIC,EADqB,QACYD,EACrC,OAAOrF,KAAK4E,aAAaU,EAAWtF,KAAKE,oBAAoBmF,KAIjExF,EAAOc,UAAU4E,wBAA0B,WACvC,IAAIC,EAAMxF,KACV,OAAOA,KAAKyF,iBAAiB3C,IAAI,SAAA4C,GAe7B,OAXAA,EAAUC,SAAS9C,KAAK,SAAmBG,EAAGC,GAC1C,IAAI2C,EAAc5C,EAAErB,KAAKP,IAAM4B,EAAErB,KAAKP,IAAI8B,YAAcF,EAAErB,KAAKuB,YAC3D2C,EAAc5C,EAAEtB,KAAKP,IAAM6B,EAAEtB,KAAKP,IAAI8B,YAAcD,EAAEtB,KAAKuB,YAC/D,OAAI0C,EAAcC,EACP,EAEPD,EAAcC,GACN,EAEL,IAEJ,IAAIjG,MAAM4F,EAAIN,SAAUQ,MAIvC7F,EAAOc,UAAUmF,aAAe,WAC5B,IAAIC,KAIJ,OAHA/F,KAAKC,UAAUmC,QAAQ,SAAAjB,GACnB4E,EAAY5E,EAAQC,IAAIC,IAAMF,IAE3B4E,GAIJlG","file":"../../../scripts/mvc/history/job-dag.js","sourcesContent":["define([\"utils/graph\", \"utils/add-logging\"], function(GRAPH, addLogging) {\n    \"use strict\";\n\n    // ============================================================================\n    var _super = GRAPH.Graph;\n    /** A Directed acyclic Graph built from a history's job data.\n *      Reads in job json, filters and process that json, and builds a graph\n *      using the connections between job inputs and outputs.\n */\n    var JobDAG = function(options) {\n        options = options || {};\n        var self = this;\n        //this.logger = console;\n\n        self.filters = [];\n\n        // instance vars\n        //TODO: needed?\n        self._jobsData = [];\n        self._historyContentsMap = {};\n        self._toolMap = {};\n\n        self._outputIdToJobMap = {};\n        self.noInputJobs = [];\n        self.noOutputJobs = [];\n\n        //TODO: save these?\n        self.filteredSetMetadata = [];\n        self.filteredErroredJobs = [];\n\n        self.dataKeys = [\"jobs\", \"historyContents\", \"tools\"];\n        _super.call(self, true, _.pick(options, self.dataKeys), _.omit(options, self.dataKeys));\n    };\n    JobDAG.prototype = new GRAPH.Graph();\n    JobDAG.prototype.constructor = JobDAG;\n\n    // add logging ability - turn off/on using the this.logger statement above\n    addLogging(JobDAG);\n\n    // ----------------------------------------------------------------------------\n    /** process jobs, options, filters, and any history data, then create the graph */\n    JobDAG.prototype.init = function _init(options) {\n        options = options || {};\n\n        var self = this;\n        self.options = _.defaults(options, {\n            excludeSetMetadata: false\n        });\n        self.filters = self._initFilters();\n\n        _super.prototype.init.call(self, options);\n        return self;\n    };\n\n    /** add job filters based on options */\n    JobDAG.prototype._initFilters = function __initFilters() {\n        var self = this,\n            filters = [];\n\n        if (self.options.excludeSetMetadata) {\n            self.filteredSetMetadata = [];\n            filters.push(function filterSetMetadata(jobData) {\n                if (jobData.job.tool_id !== \"__SET_METADATA__\") {\n                    return true;\n                }\n                self.filteredSetMetadata.push(jobData.job.id);\n                return false;\n            });\n        }\n\n        if (self.options.excludeErroredJobs) {\n            self.filteredErroredJobs = [];\n            filters.push(function filterErrored(jobData) {\n                if (jobData.job.state !== \"error\") {\n                    return true;\n                }\n                self.filteredErroredJobs.push(jobData.job.id);\n                return false;\n            });\n        }\n\n        // all outputs deleted\n        // all outputs hidden\n\n        if (_.isArray(self.options.filters)) {\n            filters = filters.concat(self.options.filters);\n        }\n        self.debug(\"filters len:\", filters.length);\n        return filters;\n    };\n\n    /**  */\n    JobDAG.prototype.read = function _read(data) {\n        var self = this;\n        if (_.has(data, \"historyContents\") && _.has(data, \"jobs\") && _.has(data, \"tools\")) {\n            // a job dag is composed of these three elements:\n            //  clone the 3 data sources into the DAG, processing the jobs finally using the history and tools\n            self\n                .preprocessHistoryContents(data.historyContents || [])\n                .preprocessTools(data.tools || {})\n                .preprocessJobs(data.jobs || []);\n\n            // filter jobs and create the vertices and edges of the job DAG\n            self.createGraph(self._filterJobs());\n            return self;\n        }\n        return _super.prototype.read.call(this, data);\n    };\n\n    /**  */\n    JobDAG.prototype.preprocessHistoryContents = function _preprocessHistoryContents(historyContents) {\n        this.info(\"processing history\");\n        var self = this;\n        self._historyContentsMap = {};\n\n        historyContents.forEach(function(content, i) {\n            self._historyContentsMap[content.id] = _.clone(content);\n        });\n        return self;\n    };\n\n    /**  */\n    JobDAG.prototype.preprocessTools = function _preprocessTools(tools) {\n        this.info(\"processing tools\");\n        var self = this;\n        self._toolMap = {};\n\n        _.each(tools, function(tool, id) {\n            self._toolMap[id] = _.clone(tool);\n        });\n        return self;\n    };\n\n    /** sort the cloned jobs, decorate with tool and history contents info, and store in prop array */\n    JobDAG.prototype.preprocessJobs = function _preprocessJobs(jobs) {\n        this.info(\"processing jobs\");\n        var self = this;\n        self._outputIdToJobMap = {};\n\n        self._jobsData = self.sort(jobs).map(function(job) {\n            return self.preprocessJob(_.clone(job));\n        });\n        //console.debug( JSON.stringify( self._jobsData, null, '    ' ) );\n        //console.debug( JSON.stringify( self._outputIdToJobMap, null, '    ' ) );\n        return self;\n    };\n\n    /** sort the jobs based on update time */\n    JobDAG.prototype.sort = function _sort(jobs) {\n        function cmpCreate(a, b) {\n            if (a.create_time > b.create_time) {\n                return 1;\n            }\n            if (a.create_time < b.create_time) {\n                return -1;\n            }\n            return 0;\n        }\n        return jobs.sort(cmpCreate);\n    };\n\n    /** decorate with input/output datasets and tool */\n    JobDAG.prototype.preprocessJob = function _preprocessJob(job, index) {\n        //this.info( 'preprocessJob', job, index );\n        var self = this,\n            jobData = { job: job };\n\n        jobData.inputs = self._processInputs(job);\n        if (_.size(jobData.inputs) === 0) {\n            self.noInputJobs.push(job.id);\n        }\n        jobData.outputs = self._processOutputs(job);\n        if (_.size(jobData.outputs) === 0) {\n            self.noOutputJobs.push(job.id);\n        }\n\n        jobData.tool = self._toolMap[job.tool_id];\n\n        //self.info( '\\t jobData:', jobData );\n        return jobData;\n    };\n\n    /**\n */\n    JobDAG.prototype._processInputs = function __processInputs(job) {\n        var self = this,\n            inputs = job.inputs,\n            inputMap = {};\n        _.each(inputs, function(input, nameInJob) {\n            input = _.clone(self._validateInputOutput(input));\n            input.name = nameInJob;\n            // since this is a DAG and we're processing in order of create time,\n            //  the inputs for this job will already be listed in _outputIdToJobMap\n            //  TODO: we can possibly exploit this\n            //console.debug( 'input in _outputIdToJobMap', self._outputIdToJobMap[ input.id ] );\n            input.content = self._historyContentsMap[input.id];\n            inputMap[input.id] = input;\n        });\n        return inputMap;\n    };\n\n    /**\n */\n    JobDAG.prototype._validateInputOutput = function __validateInputOutput(inputOutput) {\n        if (!inputOutput.id) {\n            throw new Error(\"No id on job input/output: \", JSON.stringify(inputOutput));\n        }\n        if (!inputOutput.src || inputOutput.src !== \"hda\") {\n            throw new Error(\"Bad src on job input/output: \", JSON.stringify(inputOutput));\n        }\n        return inputOutput;\n    };\n\n    /**\n */\n    JobDAG.prototype._processOutputs = function __processOutputs(job) {\n        var self = this,\n            outputs = job.outputs,\n            outputMap = {};\n        _.each(outputs, function(output, nameInJob) {\n            output = _.clone(self._validateInputOutput(output));\n            output.name = nameInJob;\n            // add dataset content to jobData\n            output.content = self._historyContentsMap[output.id];\n            outputMap[output.id] = output;\n\n            self._outputIdToJobMap[output.id] = job.id;\n        });\n        return outputMap;\n    };\n\n    /**  */\n    JobDAG.prototype._filterJobs = function __filterJobs() {\n        var self = this;\n        return self._jobsData.filter(function(j, i) {\n            return self._filterJob(j, i);\n        });\n    };\n\n    /**\n */\n    JobDAG.prototype._filterJob = function _filterJob(jobData, index) {\n        // apply filters after processing job allowing access to the additional data above inside the filters\n        var self = this;\n        for (var i = 0; i < self.filters.length; i++) {\n            if (!self.filters[i].call(self, jobData)) {\n                self.debug(\"\\t job\", jobData.job.id, \" has been filtered out by function:\\n\", self.filters[i]);\n                return false;\n            }\n        }\n        return true;\n    };\n\n    /** Walk all the jobs (vertices), attempting to find connections\n *  between datasets used as both inputs and outputs (edges)\n */\n    JobDAG.prototype.createGraph = function _createGraph(jobsData) {\n        var self = this;\n        self.debug(\"connections:\");\n        //console.debug( jobsData );\n\n        _.each(jobsData, function(jobData) {\n            var id = jobData.job.id;\n            self.debug(\"\\t\", id, jobData);\n            self.createVertex(id, jobData);\n        });\n        _.each(jobsData, function(jobData) {\n            var targetId = jobData.job.id;\n            _.each(jobData.inputs, function(input, inputId) {\n                //console.debug( '\\t\\t target input:', inputId, input );\n                var sourceId = self._outputIdToJobMap[inputId];\n                //console.debug( '\\t\\t source job id:', sourceId );\n                if (!sourceId) {\n                    var joblessVertex = self.createJobLessVertex(inputId);\n                    sourceId = joblessVertex.name;\n                }\n                //TODO:?? no checking here whether sourceId is actually in the vertex map\n                //console.debug( '\\t\\t creating edge, source:', sourceId, self.vertices[ sourceId ] );\n                //console.debug( '\\t\\t creating edge, target:', targetId, self.vertices[ targetId ] );\n                self.createEdge(sourceId, targetId, self.directed, {\n                    dataset: inputId\n                });\n            });\n        });\n        //console.debug( self.toVerticesAndEdges().edges );\n\n        self.debug(\"final graph: \", JSON.stringify(self.toVerticesAndEdges(), null, \"  \"));\n        return self;\n    };\n\n    /** Return a 'mangled' version of history contents id to prevent contents <-> job id collision */\n    JobDAG.prototype.createJobLessVertex = function _createJobLessVertex(contentId) {\n        // currently, copied contents are the only history contents without jobs (that I know of)\n        //note: following needed to prevent id collision btwn content and jobs in vertex map\n        var JOBLESS_ID_MANGLER = \"copy-\",\n            mangledId = JOBLESS_ID_MANGLER + contentId;\n        return this.createVertex(mangledId, this._historyContentsMap[contentId]);\n    };\n\n    /** Override to re-sort (ugh) jobs in each component by update time */\n    JobDAG.prototype.weakComponentGraphArray = function() {\n        var dag = this;\n        return this.weakComponents().map(function(component) {\n            //TODO: this seems to belong above (in sort) - why isn't it preserved?\n            // note: using create_time (as opposed to update_time)\n            //  since update_time for jobless/copied datasets is changes more often\n            component.vertices.sort(function cmpCreate(a, b) {\n                var aCreateTime = a.data.job ? a.data.job.create_time : a.data.create_time,\n                    bCreateTime = b.data.job ? b.data.job.create_time : b.data.create_time;\n                if (aCreateTime > bCreateTime) {\n                    return 1;\n                }\n                if (aCreateTime < bCreateTime) {\n                    return -1;\n                }\n                return 0;\n            });\n            return new Graph(dag.directed, component);\n        });\n    };\n\n    JobDAG.prototype._jobsDataMap = function() {\n        var jobsDataMap = {};\n        this._jobsData.forEach(function(jobData) {\n            jobsDataMap[jobData.job.id] = jobData;\n        });\n        return jobsDataMap;\n    };\n\n    // ============================================================================\n    return JobDAG;\n});\n"]}